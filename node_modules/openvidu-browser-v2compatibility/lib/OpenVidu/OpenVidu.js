"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.OpenVidu = void 0;
const livekit_client_1 = require("livekit-client");
const OpenViduLogger_1 = require("../OpenViduInternal/Logger/OpenViduLogger");
const Platform_1 = require("../OpenViduInternal/Utils/Platform");
const Publisher_1 = require("./Publisher");
const Session_1 = require("./Session");
const OpenViduError_1 = require("../OpenViduInternal/Enums/OpenViduError");
const LocalRecorder_1 = require("./LocalRecorder");
const VideoInsertMode_1 = require("../OpenViduInternal/Enums/VideoInsertMode");
const StreamPropertyChangedEvent_1 = require("../OpenViduInternal/Events/StreamPropertyChangedEvent");
const InternalSignalTypes_1 = require("../OpenViduInternal/Interfaces/Private/InternalSignalTypes");
/**
 * @hidden
 */
const packageJson = require('../../package.json');
/**
 * @hidden
 */
let platform = Platform_1.PlatformUtils.getInstance();
/**
 * @hidden
 */
const logger = OpenViduLogger_1.OpenViduLogger.getInstance();
/**
 * Entrypoint of OpenVidu Browser library.
 * Use it to initialize objects of type {@link Session}, {@link Publisher} and {@link LocalRecorder}
 */
class OpenVidu {
    constructor() {
        /**
         * @hidden
         */
        this.publishers = [];
        /**
         * ! Not supported in Adapter
         * @hidden
         */
        this.advancedConfiguration = {};
        logger.log(`
            %cðŸŽ‰ OpenVidu Browser V2Compatibility v${packageJson.version} ðŸŽ‰%c
        `, 'font-weight: bold; font-size: 20px; color: green;', 'font-weight: bold; font-size: 15px;');
        this.libraryVersion = packageJson.version;
        logger.info('OpenVidu initialized');
        logger.info('Platform detected: ' + platform.getDescription());
        logger.info('openvidu-browser-v2compatibility version: ' + this.libraryVersion);
        if (platform.isMobileDevice() || platform.isReactNative()) {
            // Listen to orientationchange only on mobile devices
            this.onOrientationChanged(() => {
                this.publishers.forEach((publisher) => {
                    if (publisher.stream.isReadyToAttach && !!publisher.stream && !!publisher.stream.hasVideo) {
                        this.sendNewVideoDimensionsIfRequired(publisher, 'deviceRotated', 80, 10);
                    }
                });
            });
        }
    }
    /**
     * Returns new session
     */
    initSession() {
        return (this.session = new Session_1.Session(this));
    }
    /**
     * Returns a new publisher
     *
     * #### Events dispatched
     *
     * The {@link Publisher} object will dispatch an `accessDialogOpened` event, only if the pop-up shown by the browser to request permissions for the camera is opened. You can use this event to alert the user about granting permissions
     * for your website. An `accessDialogClosed` event will also be dispatched after user clicks on "Allow" or "Block" in the pop-up.
     *
     * The {@link Publisher} object will dispatch an `accessAllowed` or `accessDenied` event once it has been granted access to the requested input devices or not.
     *
     * The {@link Publisher} object will dispatch a `videoElementCreated` event once a HTML video element has been added to DOM (only if you
     * [let OpenVidu take care of the video players](/en/stable/cheatsheet/manage-videos/#let-openvidu-take-care-of-the-video-players)). See {@link VideoElementEvent} to learn more.
     *
     * The {@link Publisher} object will dispatch a `streamPlaying` event once the local streams starts playing. See {@link StreamManagerEvent} to learn more.
     *
     * @param targetElement  HTML DOM element (or its `id` attribute) in which the video element of the Publisher will be inserted (see {@link PublisherProperties.insertMode}). If *null* or *undefined* no default video will be created for this Publisher.
     * You can always call method {@link Publisher.addVideoElement} or {@link Publisher.createVideoElement} to manage the video elements on your own (see [Manage video players](/en/stable/cheatsheet/manage-videos) section)
     * @param completionHandler `error` parameter is null if `initPublisher` succeeds, and is defined if it fails.
     *                          `completionHandler` function is called before the Publisher dispatches an `accessAllowed` or an `accessDenied` event
     */
    initPublisher(targetElement, param2, param3) {
        const properties = this.initializeProperties(param2);
        // Initialize completionHandler with a default empty function
        let completionHandler = typeof param2 === 'function'
            ? param2 // If param2 is a function, use it as completionHandler
            : param3 || (() => { }); // If param3 exists, use it as completionHandler; otherwise, use a default empty function
        // Create a new Publisher instance with the specified target element, properties, and context (this)
        const publisher = new Publisher_1.Publisher(targetElement, properties, this);
        publisher
            .initialize()
            .then(() => {
            logger.log('Publisher initialized');
            completionHandler(undefined);
        })
            .catch((error) => {
            completionHandler(error);
        });
        this.publishers.push(publisher);
        return publisher;
    }
    initPublisherAsync(targetElement, properties) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!!properties) {
                return yield this.initPublisher(targetElement, properties);
            }
            else {
                return yield this.initPublisher(targetElement);
            }
        });
    }
    /**
     * Collects information about the media input devices available on the system. You can pass property `deviceId` of a {@link Device} object as value of `audioSource` or `videoSource` properties in {@link initPublisher} method
     */
    getDevices() {
        return __awaiter(this, void 0, void 0, function* () {
            const devices = yield livekit_client_1.Room.getLocalDevices();
            const deviceList = [];
            devices.forEach((device) => {
                if (device.kind === 'audioinput' || device.kind === 'videoinput') {
                    deviceList.push({
                        deviceId: device.deviceId,
                        label: device.label,
                        kind: device.kind
                    });
                }
            });
            return deviceList;
        });
    }
    /**
     * Get a MediaStream object that you can customize before calling {@link initPublisher} (pass _MediaStreamTrack_ property of the _MediaStream_ value resolved by the Promise as `audioSource` or `videoSource` properties in {@link initPublisher})
     *
     * Parameter `options` is the same as in {@link initPublisher} second parameter (of type {@link PublisherProperties}), but only the following properties will be applied: `audioSource`, `videoSource`, `frameRate`, `resolution`
     *
     * To customize the Publisher's video, the API for HTMLCanvasElement is very useful. For example, to get a black-and-white video at 10 fps and HD resolution with no sound:
     * ```
     * var OV = new OpenVidu();
     * var FRAME_RATE = 10;
     *
     * OV.getUserMedia({
     *    audioSource: false,
     *    videoSource: undefined,
     *    resolution: '1280x720',
     *    frameRate: FRAME_RATE
     * })
     * .then(mediaStream => {
     *
     *    var videoTrack = mediaStream.getVideoTracks()[0];
     *    var video = document.createElement('video');
     *    video.srcObject = new MediaStream([videoTrack]);
     *
     *    var canvas = document.createElement('canvas');
     *    var ctx = canvas.getContext('2d');
     *    ctx.filter = 'grayscale(100%)';
     *
     *    video.addEventListener('play', () => {
     *      var loop = () => {
     *        if (!video.paused && !video.ended) {
     *          ctx.drawImage(video, 0, 0, 300, 170);
     *          setTimeout(loop, 1000/ FRAME_RATE); // Drawing at 10 fps
     *        }
     *      };
     *      loop();
     *    });
     *    video.play();
     *
     *    var grayVideoTrack = canvas.captureStream(FRAME_RATE).getVideoTracks()[0];
     *    var publisher = this.OV.initPublisher(
     *      myHtmlTarget,
     *      {
     *        audioSource: false,
     *        videoSource: grayVideoTrack
     *      });
     * });
     * ```
     */
    getUserMedia(properties) {
        var _a, _b, _c;
        return __awaiter(this, void 0, void 0, function* () {
            try {
                const myConstraints = this.generateMediaConstraints(properties);
                const { constraints, audioTrack, videoTrack } = myConstraints;
                if (this.isMediaTracksProvided(myConstraints)) {
                    // No need to call getUserMedia at all. Both tracks provided, or only AUDIO track provided or only VIDEO track provided
                    return this.generateNewMediaStream(audioTrack, videoTrack);
                }
                // getUserMedia must be called. AUDIO or VIDEO are requesting a new track
                // Delete already provided constraints for audio or video
                if (!!videoTrack) {
                    delete myConstraints.constraints.video;
                }
                if (!!audioTrack) {
                    delete myConstraints.constraints.audio;
                }
                if (typeof properties.videoSource === 'string') {
                    // Video is deviceId or screen sharing
                    if (this.isScreenShare(properties.videoSource)) {
                        // Video is screen sharing
                        const screenTrackOptions = this.generateScreenCaptureOptionsFromConstraints(constraints);
                        const sceenTracks = yield (0, livekit_client_1.createLocalScreenTracks)(screenTrackOptions);
                        let audioTrack;
                        audioTrack = sceenTracks.find((track) => track.kind === livekit_client_1.Track.Kind.Audio);
                        // If no screen audio, check if other audio tracks must be set
                        if (!audioTrack) {
                            if (properties.audioSource === true || properties.audioSource === undefined) {
                                audioTrack = yield (0, livekit_client_1.createLocalAudioTrack)();
                            }
                            else if (properties.audioSource instanceof MediaStreamTrack) {
                                audioTrack = new livekit_client_1.LocalAudioTrack(properties.audioSource, undefined, true);
                            }
                        }
                        const audioStreamTrack = audioTrack === null || audioTrack === void 0 ? void 0 : audioTrack.mediaStreamTrack;
                        const videoStreamTrack = (_a = sceenTracks.find((track) => track.kind === livekit_client_1.Track.Kind.Video)) === null || _a === void 0 ? void 0 : _a.mediaStreamTrack;
                        return this.generateNewMediaStream(audioStreamTrack, videoStreamTrack);
                    }
                    else {
                        // Video is deviceId. Can perform getUserMedia below with already calculated constraints
                    }
                }
                // Use already calculated constraints
                try {
                    // const constraints = myConstraints.constraints;
                    const audioOpts = this.generateAudioCaptureOptionsFromContraints(constraints);
                    const videoOpts = this.generateVideoCaptureOptionsFromContraints(constraints);
                    const trackOpts = { audio: audioOpts, video: videoOpts };
                    const tracks = yield (0, livekit_client_1.createLocalTracks)(trackOpts);
                    const audioStreamTrack = (_b = tracks.find((track) => track.kind === livekit_client_1.Track.Kind.Audio)) === null || _b === void 0 ? void 0 : _b.mediaStreamTrack;
                    const videoStreamTrack = (_c = tracks.find((track) => track.kind === livekit_client_1.Track.Kind.Video)) === null || _c === void 0 ? void 0 : _c.mediaStreamTrack;
                    return this.generateNewMediaStream(audioStreamTrack, videoStreamTrack);
                }
                catch (error) {
                    let errorName;
                    const errorMessage = error.toString();
                    if (properties.videoSource === 'screen') {
                        errorName = OpenViduError_1.OpenViduErrorName.SCREEN_CAPTURE_DENIED;
                    }
                    else {
                        errorName = OpenViduError_1.OpenViduErrorName.DEVICE_ACCESS_DENIED;
                    }
                    throw new OpenViduError_1.OpenViduError(errorName, errorMessage);
                }
            }
            catch (error) {
                throw error;
            }
        });
    }
    /**
     * Disable all logging except error level
     */
    enableProdMode() {
        logger.enableProdMode();
    }
    /**
     * @hidden
     */
    onOrientationChanged(handler) {
        globalThis.addEventListener('orientationchange', handler);
    }
    /**
     * @hidden
     */
    sendNewVideoDimensionsIfRequired(publisher, reason, WAIT_INTERVAL, MAX_ATTEMPTS) {
        var _a, _b, _c, _d;
        let attempts = 0;
        const oldWidth = ((_b = (_a = publisher === null || publisher === void 0 ? void 0 : publisher.stream) === null || _a === void 0 ? void 0 : _a.videoDimensions) === null || _b === void 0 ? void 0 : _b.width) || 0;
        const oldHeight = ((_d = (_c = publisher === null || publisher === void 0 ? void 0 : publisher.stream) === null || _c === void 0 ? void 0 : _c.videoDimensions) === null || _d === void 0 ? void 0 : _d.height) || 0;
        const repeatUntilChangeOrMaxAttempts = setInterval(() => __awaiter(this, void 0, void 0, function* () {
            attempts++;
            if (attempts > MAX_ATTEMPTS) {
                clearTimeout(repeatUntilChangeOrMaxAttempts);
                logger.warn(`Video dimensions have not changed in ${MAX_ATTEMPTS * WAIT_INTERVAL}ms after a change in the video track (still ${oldWidth}x${oldHeight}). No event will be dispatched`);
                return;
            }
            try {
                const newDimensions = yield publisher.stream.getVideoDimensions();
                if (newDimensions.width !== oldWidth || newDimensions.height !== oldHeight) {
                    clearTimeout(repeatUntilChangeOrMaxAttempts);
                    this.sendVideoDimensionsChangedEvent(publisher, reason, oldWidth, oldHeight, newDimensions.width, newDimensions.height);
                }
            }
            catch (error) {
                logger.error('Error getting video dimensions after a change in the video track', error);
            }
        }), WAIT_INTERVAL);
    }
    /**
     * @hidden
     */
    sendVideoDimensionsChangedEvent(publisher, reason, oldWidth, oldHeight, newWidth, newHeight) {
        return __awaiter(this, void 0, void 0, function* () {
            const changedProperty = 'videoDimensions';
            const newValue = { width: newWidth, height: newHeight };
            const oldValue = { width: oldWidth, height: oldHeight };
            publisher.stream.videoDimensions = {
                width: newWidth || 0,
                height: newHeight || 0
            };
            const sessionEvent = new StreamPropertyChangedEvent_1.StreamPropertyChangedEvent(this.session, publisher.stream, changedProperty, newValue, oldValue, reason);
            const streamManagerEvent = new StreamPropertyChangedEvent_1.StreamPropertyChangedEvent(publisher, publisher.stream, changedProperty, newValue, oldValue, reason);
            // Trigger local events
            this.session.publicEmmiter.emitEvent('streamPropertyChanged', [sessionEvent]);
            publisher.publicEmmiter.emitEvent('streamPropertyChanged', [streamManagerEvent]);
            // Send signal to other participants
            // The signals handler will send the event from the session and the subscriber
            const opt = {
                data: JSON.stringify({
                    sentFromServer: false,
                    payload: { changedProperty, newValue, oldValue, reason, participantIdentity: this.session.room.localParticipant.identity }
                }),
                type: `${InternalSignalTypes_1.InternalSignalType.CUSTOM_CLIENT_SIGNAL_PREFIX}${InternalSignalTypes_1.InternalSignalType.OPENVIDU_STREAM_PROPERTY_CHANGED}`
            };
            if (this.session.isSessionConnected()) {
                yield this.session.signalInternal(opt, false);
            }
        });
    }
    /**
     * @hidden
     */
    generateNewMediaStream(audioTrack, videoTrack) {
        const mediaStream = new MediaStream();
        if (!!audioTrack) {
            mediaStream.addTrack(audioTrack);
        }
        if (!!videoTrack) {
            mediaStream.addTrack(videoTrack);
        }
        return mediaStream;
    }
    /**
     * Generates the media constraints based on the provided publisher properties.
     * @param publisherProperties - The properties of the publisher.
     * @returns A promise that resolves to the custom media stream constraints.
     * @throws {OpenViduError} If the audioSource and videoSource are both set to false or null.
     * @hidden
     */
    generateMediaConstraints(publisherProperties) {
        let myConstraints = {
            audioTrack: undefined,
            videoTrack: undefined,
            constraints: {
                audio: undefined,
                video: undefined
            }
        };
        const audioSource = publisherProperties.audioSource;
        const videoSource = publisherProperties.videoSource;
        // CASE 1: null/false
        if (audioSource === null || audioSource === false) {
            // No audio track
            myConstraints.constraints.audio = false;
        }
        if (videoSource === null || videoSource === false) {
            // No video track
            myConstraints.constraints.video = false;
        }
        if (myConstraints.constraints.audio === false && myConstraints.constraints.video === false) {
            // ERROR! audioSource and videoSource cannot be both false at the same time
            const error = new OpenViduError_1.OpenViduError(OpenViduError_1.OpenViduErrorName.NO_INPUT_SOURCE_SET, "Properties 'audioSource' and 'videoSource' cannot be set to false or null at the same time");
            throw error;
        }
        // CASE 2: MediaStreamTracks
        if (typeof MediaStreamTrack !== 'undefined' && audioSource instanceof MediaStreamTrack) {
            // Already provided audio track
            myConstraints.audioTrack = audioSource;
        }
        if (typeof MediaStreamTrack !== 'undefined' && videoSource instanceof MediaStreamTrack) {
            // Already provided video track
            myConstraints.videoTrack = videoSource;
        }
        // CASE 3: Default tracks
        if (audioSource === undefined) {
            myConstraints.constraints.audio = true;
        }
        if (videoSource === undefined) {
            myConstraints.constraints.video = {
                width: {
                    ideal: 640
                },
                height: {
                    ideal: 480
                }
            };
        }
        // CASE 3.5: give values to resolution and frameRate if video not null/false
        if (videoSource !== null && videoSource !== false) {
            if (!!publisherProperties.resolution) {
                const widthAndHeight = publisherProperties.resolution.toLowerCase().split('x');
                const idealWidth = Number(widthAndHeight[0]);
                const idealHeight = Number(widthAndHeight[1]);
                myConstraints.constraints.video = {
                    width: {
                        ideal: idealWidth
                    },
                    height: {
                        ideal: idealHeight
                    }
                };
            }
            if (!!publisherProperties.frameRate) {
                myConstraints.constraints.video.frameRate = { ideal: publisherProperties.frameRate };
            }
        }
        // CASE 4: deviceId or screen sharing
        myConstraints = this.configureDeviceIdOrScreensharing(myConstraints, publisherProperties);
        return myConstraints;
    }
    /**
     * Set OpenVidu advanced configuration options. `configuration` is an object of type {@link OpenViduAdvancedConfiguration}. Call this method to override previous values at any moment.
     */
    setAdvancedConfiguration(configuration) {
        this.advancedConfiguration = configuration;
    }
    /**
     * Returns a new local recorder for recording streams straight away from the browser
     * @param stream  Stream to record
     */
    initLocalRecorder(stream) {
        return new LocalRecorder_1.LocalRecorder(stream);
    }
    /**
     * Checks if the browser supports screen-sharing. Desktop Chrome, Firefox and Opera support screen-sharing
     * @returns 1 if the browser supports screen-sharing, 0 otherwise
     */
    checkScreenSharingCapabilities() {
        return platform.canScreenShare();
    }
    /**
     * @hidden
     */
    configureDeviceIdOrScreensharing(myConstraints, publisherProperties) {
        const audioSource = publisherProperties.audioSource;
        const videoSource = publisherProperties.videoSource;
        if (typeof audioSource === 'string') {
            myConstraints.constraints.audio = { deviceId: { exact: audioSource } };
        }
        if (typeof videoSource === 'string') {
            if (myConstraints.constraints.video && typeof myConstraints.constraints.video === 'object') {
                myConstraints.constraints.video.deviceId = { exact: videoSource };
            }
            else if (myConstraints.constraints.video === undefined) {
                myConstraints.constraints.video = { deviceId: { exact: videoSource } };
            }
            if (this.isScreenShare(videoSource)) {
                if (!this.checkScreenSharingCapabilities()) {
                    const error = new OpenViduError_1.OpenViduError(OpenViduError_1.OpenViduErrorName.SCREEN_SHARING_NOT_SUPPORTED, 'You can only screen share in desktop Chrome, Firefox, Opera, Safari (>=13.0), Edge (>= 80) or Electron. Detected client: ' +
                        platform.getName() +
                        ' ' +
                        platform.getVersion());
                    throw error;
                }
                // Screen sharing is supported
                if (platform.isElectron()) {
                    const prefix = 'screen:';
                    const videoSourceString = videoSource;
                    const electronScreenId = videoSourceString.substr(videoSourceString.indexOf(prefix) + prefix.length);
                    myConstraints.constraints.video = {
                        mandatory: {
                            chromeMediaSource: 'desktop',
                            chromeMediaSourceId: electronScreenId
                        }
                    };
                }
            }
            else {
                // Video source is not screen sharing
                if (audioSource === 'screen') {
                    logger.warn('Parameter "audioSource" is set to "screen", which means requesting audio from screen sharing source. But "videoSource" is not set to "screen". No audio source will be requested');
                    myConstraints.constraints.audio = false;
                }
            }
        }
        return myConstraints;
    }
    isScreenShare(videoSource) {
        return videoSource === 'screen' || videoSource === 'window' || (platform.isElectron() && videoSource.startsWith('screen:'));
    }
    initializeProperties(param2) {
        let properties = {};
        const hasValidParam2 = param2 && typeof param2 !== 'function';
        const defaultProperties = {
            insertMode: VideoInsertMode_1.VideoInsertMode.APPEND,
            mirror: true,
            publishAudio: true,
            publishVideo: true,
            resolution: '640x480'
        };
        if (hasValidParam2) {
            // Matches 'initPublisher(targetElement, properties)' or 'initPublisher(targetElement, properties, completionHandler)'
            properties = param2;
            properties = {
                audioSource: typeof properties.audioSource !== 'undefined' ? properties.audioSource : undefined,
                frameRate: typeof properties.frameRate !== 'undefined' ? properties.frameRate : undefined,
                insertMode: this.getInsertMode(properties),
                mirror: typeof properties.mirror !== 'undefined' ? properties.mirror : true,
                publishAudio: typeof properties.publishAudio !== 'undefined' ? properties.publishAudio : true,
                publishVideo: typeof properties.publishVideo !== 'undefined' ? properties.publishVideo : true,
                resolution: typeof properties.resolution !== 'undefined' ? properties.resolution : '640x480',
                videoSource: typeof properties.videoSource !== 'undefined' ? properties.videoSource : undefined,
                videoSimulcast: properties.videoSimulcast,
                filter: properties.filter
            };
        }
        else {
            // Matches 'initPublisher(targetElement)' or 'initPublisher(targetElement, completionHandler)'
            properties = defaultProperties;
        }
        return properties;
    }
    getInsertMode(properties) {
        return typeof properties.insertMode !== 'undefined'
            ? typeof properties.insertMode === 'string'
                ? VideoInsertMode_1.VideoInsertMode[properties.insertMode]
                : properties.insertMode
            : VideoInsertMode_1.VideoInsertMode.APPEND;
    }
    /**
     * Checks if media tracks are provided based on the given constraints.
     * @param constraints - The custom media stream constraints.
     * @returns A boolean indicating whether media tracks are provided or not.
     * @hidden
     */
    isMediaTracksProvided(constraints) {
        const { videoTrack, audioTrack, constraints: { video, audio } = {} } = constraints;
        const isVideoProvided = !!videoTrack || (typeof video === 'boolean' && !video);
        const isAudioProvided = !!audioTrack || (typeof audio === 'boolean' && !audio);
        return isVideoProvided && isAudioProvided;
    }
    /**
     *
     * @hidden
     */
    generateVideoCaptureOptionsFromContraints(constraints) {
        var _a;
        if (typeof constraints.video === 'boolean') {
            return constraints.video;
        }
        const resolution = this.getResolution(constraints);
        return {
            deviceId: (_a = constraints.video) === null || _a === void 0 ? void 0 : _a.deviceId,
            // facingMode: constraints.video?.facingMode,
            resolution: {
                width: resolution.width,
                height: resolution.height,
                frameRate: resolution.frameRate
                // aspectRatio: resolution.aspectRatio
            }
        };
    }
    /**
     *
     * @hidden
     */
    generateAudioCaptureOptionsFromContraints(constraints) {
        var _a;
        if (typeof constraints.audio === 'boolean') {
            return constraints.audio;
        }
        else {
            return {
                deviceId: (_a = constraints.audio) === null || _a === void 0 ? void 0 : _a.deviceId
                // autoGainControl: constraints.audio?.autoGainControl,
                // channelCount: constraints.audio?.channelCount,
                // echoCancellation: constraints.audio?.echoCancellation,
                // latency: constraints.audio?.latency,
                // noiseSuppression: constraints.audio?.noiseSuppression,
                // sampleRate: constraints.audio?.sampleRate,
                // sampleSize: constraints.audio?.sampleSize,
            };
        }
    }
    /**
     * @hidden
     */
    generateScreenCaptureOptionsFromConstraints(constraints) {
        var _a, _b, _c;
        let screenWithAudio = false;
        if (typeof constraints.audio === 'boolean') {
            screenWithAudio = false;
        }
        else {
            if (typeof ((_a = constraints.audio) === null || _a === void 0 ? void 0 : _a.deviceId) === 'string') {
                screenWithAudio = ((_b = constraints.audio) === null || _b === void 0 ? void 0 : _b.deviceId) === 'screen';
            }
            else if (((_c = constraints.audio) === null || _c === void 0 ? void 0 : _c.deviceId) && typeof constraints.audio.deviceId === 'object') {
                screenWithAudio = constraints.audio.deviceId.exact === 'screen';
            }
        }
        return {
            audio: screenWithAudio,
            video: true,
            systemAudio: 'include'
            // resolution: {
            //     width,
            //     height,
            //     frameRate
            // }
            // controller: constraints.video?.controller,
            // selfBrowserSurface: constraints.video?.selfBrowserSurface,
            // surfaceSwitching: constraints.video?.surfaceSwitching,
            // contentHint: constraints.video?.contentHint,
            // suppressLocalAudioPlayback: constraints.video?.suppressLocalAudioPlayback,
            // preferCurrentTab: constraints.video?.preferCurrentTab,
        };
    }
    /**
     *
     * @hidden
     */
    getResolution(constraints) {
        try {
            const videoSource = constraints.video;
            let width = 640;
            let height = 480;
            let frameRate = 30;
            if (typeof videoSource === 'object') {
                if (typeof videoSource.width === 'number') {
                    width = videoSource.width;
                }
                else if (videoSource.width && typeof videoSource.width === 'object') {
                    width = videoSource.width.ideal || videoSource.width.exact || width;
                }
                if (typeof videoSource.height === 'number') {
                    height = videoSource.height;
                }
                else if (videoSource.height && typeof videoSource.height === 'object') {
                    height = videoSource.height.ideal || videoSource.height.exact || height;
                }
                if (typeof videoSource.frameRate === 'number') {
                    frameRate = videoSource.frameRate;
                }
                else if (videoSource.frameRate && typeof videoSource.frameRate === 'object') {
                    frameRate = videoSource.frameRate.ideal || videoSource.frameRate.exact || frameRate;
                }
            }
            else if (typeof videoSource === 'boolean') {
                width = videoSource ? 640 : 0;
                height = videoSource ? 480 : 0;
            }
            return { width, height, frameRate };
        }
        catch (error) {
            logger.warn('Invalid resolution provided in PublisherProperties. Setting default value (640x480)');
            return { width: 640, height: 480, frameRate: 30 };
        }
    }
}
exports.OpenVidu = OpenVidu;
//# sourceMappingURL=OpenVidu.js.map